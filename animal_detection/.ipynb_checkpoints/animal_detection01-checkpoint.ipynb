{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66e5dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.backend import set_session as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0e738d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 5 classes.\n",
      "Found 3700 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = './Animal Classification/Training Data' # train_data 경로\n",
    "test_dir = './Animal Classification/Testing Data'   # test_data 경로\n",
    "categories = ['Cat','Cow','Dog','Elephant','Panda'] # 동물 종류\n",
    "\n",
    "# ImageDataGenerator 생성\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# ImageDataGenerator 설정\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, #학습용 이미지를 가져올 폴더명\n",
    "    classes= categories,              # Cat 폴더의 image는 label을 0으로\n",
    "                                      # Cow 폴더의 image는 label을 1로 설정한다\n",
    "    target_size=(100,100),            # 이미지를 (64, 64)를 resize\n",
    "    batch_size=20,                    # 한번에 10개의 이미지만 가져와요\n",
    "    class_mode='categorical'              # 다중분류인경우 설정\n",
    ")\n",
    "\n",
    "# ImageDataGenerator 설정\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes=categories,         \n",
    "                                      \n",
    "    target_size=(100,100),            \n",
    "    batch_size=20,                    \n",
    "    class_mode='categorical'               \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eb9fe3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model 구현\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(filters=32,                          # 32 * 3 *(3 * 3) + 32(bias) = 896\n",
    "                 kernel_size=(3,3),\n",
    "                 strides=(1,1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)))\n",
    "\n",
    "model.add(Conv2D(filters=64,                         # 32 * 63 * (3 * 3) + 64 = 18,496\n",
    "                 kernel_size=(3,3),\n",
    "                 strides=(1,1),\n",
    "                 activation='relu'))\n",
    "model.add(Dropout(0.8))                             # 드롭아웃 추가. 비율은 50%\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))                           \n",
    "          \n",
    "\n",
    "model.add(Conv2D(filters=64,                       # 64 * 64 * (3 * 3) + 64 = 36,928\n",
    "                 kernel_size=(3,3),\n",
    "                 strides=(1,1),\n",
    "                 activation='relu'))\n",
    "model.add(Dropout(0.8))                             # 드롭아웃 추가. 비율은 50%\n",
    "\n",
    "#Fully Connection Layer(CNN)의 input_layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# hidden Layer\n",
    "model.add(Dense(units=128,\n",
    "                activation='relu'))\n",
    "# output_layer\n",
    "model.add(Dense(units=5,\n",
    "                activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fcddf980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_76 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 96, 96, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 135424)            0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               17334400  \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 17,391,365\n",
      "Trainable params: 17,391,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "144084dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model이 어떻게 도착하는지를 지정\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8ea58b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 43s 113ms/step - loss: 1.5940 - accuracy: 0.3055 - val_loss: 1.3738 - val_accuracy: 0.4900\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 41s 109ms/step - loss: 1.2091 - accuracy: 0.5120 - val_loss: 1.2238 - val_accuracy: 0.5475\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 43s 113ms/step - loss: 1.0153 - accuracy: 0.6111 - val_loss: 1.2234 - val_accuracy: 0.5275\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 43s 114ms/step - loss: 0.8552 - accuracy: 0.6664 - val_loss: 1.1956 - val_accuracy: 0.5242\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 40s 107ms/step - loss: 0.7229 - accuracy: 0.7300 - val_loss: 1.0394 - val_accuracy: 0.6050\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 42s 113ms/step - loss: 0.6176 - accuracy: 0.7707 - val_loss: 1.2198 - val_accuracy: 0.5342\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 41s 109ms/step - loss: 0.5223 - accuracy: 0.8055 - val_loss: 0.8953 - val_accuracy: 0.6725\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 42s 110ms/step - loss: 0.4276 - accuracy: 0.8491 - val_loss: 1.1048 - val_accuracy: 0.6017\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 43s 114ms/step - loss: 0.3489 - accuracy: 0.8757 - val_loss: 1.0945 - val_accuracy: 0.6075\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 42s 112ms/step - loss: 0.3091 - accuracy: 0.8892 - val_loss: 0.8947 - val_accuracy: 0.6683\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 48s 128ms/step - loss: 0.2468 - accuracy: 0.9165 - val_loss: 0.9152 - val_accuracy: 0.6600\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 43s 115ms/step - loss: 0.2443 - accuracy: 0.9160 - val_loss: 0.9520 - val_accuracy: 0.6625\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 43s 114ms/step - loss: 0.2093 - accuracy: 0.9313 - val_loss: 0.9977 - val_accuracy: 0.6508\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 41s 108ms/step - loss: 0.1749 - accuracy: 0.9391 - val_loss: 1.0217 - val_accuracy: 0.6542\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 42s 112ms/step - loss: 0.1629 - accuracy: 0.9467 - val_loss: 1.1375 - val_accuracy: 0.6275\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 44s 117ms/step - loss: 0.1686 - accuracy: 0.9456 - val_loss: 1.0233 - val_accuracy: 0.6425\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 43s 115ms/step - loss: 0.1325 - accuracy: 0.9548 - val_loss: 1.0738 - val_accuracy: 0.6650\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 42s 112ms/step - loss: 0.1391 - accuracy: 0.9559 - val_loss: 1.2285 - val_accuracy: 0.6333\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 42s 113ms/step - loss: 0.1251 - accuracy: 0.9588 - val_loss: 0.9954 - val_accuracy: 0.6942\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 42s 111ms/step - loss: 0.1422 - accuracy: 0.9527 - val_loss: 1.2061 - val_accuracy: 0.6283\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_generator,\n",
    "                steps_per_epoch=375,\n",
    "                epochs=20,\n",
    "                verbose=1,\n",
    "                validation_data=test_generator,\n",
    "                validation_steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f20459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
